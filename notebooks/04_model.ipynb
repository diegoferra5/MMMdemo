{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febd45b6",
   "metadata": {},
   "source": [
    "# ML MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fb5e8",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "388a828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports básicos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports de sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcb82de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PRIMERAS 5 FILAS DEL DATASET\n",
      "==================================================\n",
      "   Digital_sat  TV_sat  OOH_sat  promo  trend  Month  holiday_a  holiday_b  \\\n",
      "0     0.142295     0.0      0.0      0      1      1          1          0   \n",
      "1     0.296500     0.0      0.0      1      2      1          0          0   \n",
      "2     0.383901     0.0      0.0      0      3      1          0          0   \n",
      "3     0.523305     0.0      0.0      1      4      1          0          0   \n",
      "4     0.461213     0.0      0.0      0      5      2          0          0   \n",
      "\n",
      "   holiday_c     Sales        Date  \n",
      "0          0  26129335  2013-01-06  \n",
      "1          0  49275222  2013-01-13  \n",
      "2          0  34377765  2013-01-20  \n",
      "3          0  46040169  2013-01-27  \n",
      "4          0  38466029  2013-02-03  \n",
      "\n",
      "==================================================\n",
      "INFORMACIÓN DEL DATASET\n",
      "==================================================\n",
      "Filas: 135\n",
      "Columnas: 11\n",
      "\n",
      "Columnas disponibles:\n",
      "['Digital_sat', 'TV_sat', 'OOH_sat', 'promo', 'trend', 'Month', 'holiday_a', 'holiday_b', 'holiday_c', 'Sales', 'Date']\n",
      "\n",
      "==================================================\n",
      "TIPOS DE DATOS\n",
      "==================================================\n",
      "Digital_sat    float64\n",
      "TV_sat         float64\n",
      "OOH_sat        float64\n",
      "promo            int64\n",
      "trend            int64\n",
      "Month            int64\n",
      "holiday_a        int64\n",
      "holiday_b        int64\n",
      "holiday_c        int64\n",
      "Sales            int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "VALORES NULOS\n",
      "==================================================\n",
      "Digital_sat    0\n",
      "TV_sat         0\n",
      "OOH_sat        0\n",
      "promo          0\n",
      "trend          0\n",
      "Month          0\n",
      "holiday_a      0\n",
      "holiday_b      0\n",
      "holiday_c      0\n",
      "Sales          0\n",
      "Date           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de saturación\n",
    "df = pd.read_csv('../data/processed/weekly_sales_saturation.csv')\n",
    "\n",
    "# Ver las primeras filas\n",
    "print(\"=\" * 50)\n",
    "print(\"PRIMERAS 5 FILAS DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(df.head())\n",
    "\n",
    "# Ver información del dataset\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Filas: {df.shape[0]}\")\n",
    "print(f\"Columnas: {df.shape[1]}\")\n",
    "print(f\"\\nColumnas disponibles:\\n{df.columns.tolist()}\")\n",
    "\n",
    "# Verificar tipos de datos\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TIPOS DE DATOS\")\n",
    "print(\"=\" * 50)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VALORES NULOS\")\n",
    "print(\"=\" * 50)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7298b5f",
   "metadata": {},
   "source": [
    "### model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4b0dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols= [\n",
    "    'Digital_sat',\n",
    "    'TV_sat',\n",
    "    'OOH_sat',\n",
    "    'promo',\n",
    "    'trend',\n",
    "    'Month',\n",
    "    'holiday_a'\n",
    "]\n",
    "\n",
    "X= df[feature_cols]\n",
    "y = df['Sales']\n",
    "dates= df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a666dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (135, 7)\n",
      "y shape: (135,)\n",
      "dates shape: (135,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"dates shape: {dates.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9b73f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 7)\n",
      "(27, 7)\n"
     ]
    }
   ],
   "source": [
    "# Divide en orden: primero train, después test\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X[:split_idx]   # Primeras 80% semanas\n",
    "X_test = X[split_idx:]    # Últimas 20% semanas\n",
    "y_train = y[:split_idx]\n",
    "y_test = y[split_idx:]\n",
    "dates_train = dates[:split_idx]\n",
    "dates_test = dates[split_idx:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75e1e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0135dcb",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "019efdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha: 10\n",
      "Mejor R² (CV): 0.5426\n",
      "   param_alpha  mean_test_score  std_test_score\n",
      "0            1         0.512095        0.473932\n",
      "1            5         0.540688        0.416775\n",
      "2           10         0.542584        0.358778\n",
      "3           20         0.520612        0.283879\n",
      "4           50         0.433179        0.196374\n",
      "5          100         0.322956        0.154940\n",
      "6          200         0.198101        0.124336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# alpha list \n",
    "param_grid = {'alpha': [1,5,10,20,50,100,200]}\n",
    "\n",
    "# time series split \n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Grid search CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= Ridge(),\n",
    "    param_grid= param_grid,\n",
    "    cv= tscv,\n",
    "    scoring= 'r2',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Mejor alpha encontrado\n",
    "print(f\"Mejor alpha: {grid_search.best_params_['alpha']}\")\n",
    "\n",
    "# Mejor score (R² en training con CV)\n",
    "print(f\"Mejor R² (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Ver todos los resultados\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df[['param_alpha', 'mean_test_score', 'std_test_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a17f5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7263623332535649\n"
     ]
    }
   ],
   "source": [
    "# Modelo final con mejor alpha\n",
    "best_model = Ridge(alpha=10)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = best_model.predict(X_train_scaled)\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c992709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set - Primeras 10 observaciones:\n",
      "     y_real        y_pred         error\n",
      "0  50783355  4.662046e+07  4.162897e+06\n",
      "1  50548507  4.611041e+07  4.438094e+06\n",
      "2  39497832  3.332889e+07  6.168941e+06\n",
      "3  48295825  4.885339e+07 -5.575609e+05\n",
      "4  39936680  3.779249e+07  2.144193e+06\n",
      "5  52123970  4.994583e+07  2.178141e+06\n",
      "6  39436926  3.891493e+07  5.219953e+05\n",
      "7  50662424  5.099743e+07 -3.350023e+05\n",
      "8  39585055  3.994663e+07 -3.615753e+05\n",
      "9  55923085  5.248337e+07  3.439715e+06\n",
      "\n",
      "Rango y_test: 34879894 - 55923085\n",
      "Rango y_pred_test: 32727452 - 52483370\n",
      "\n",
      "R² Training: 0.7531\n",
      "R² Test: 0.7264\n",
      "R² Baseline (media): -0.2153\n"
     ]
    }
   ],
   "source": [
    " #1. Compara predicciones vs valores reales\n",
    "print(\"Test Set - Primeras 10 observaciones:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'y_real': y_test[:10].values,\n",
    "    'y_pred': y_pred_test[:10],\n",
    "    'error': y_test[:10].values - y_pred_test[:10]\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# 2. Compara rangos\n",
    "print(f\"\\nRango y_test: {y_test.min():.0f} - {y_test.max():.0f}\")\n",
    "print(f\"Rango y_pred_test: {y_pred_test.min():.0f} - {y_pred_test.max():.0f}\")\n",
    "\n",
    "# 3. Verifica R² en training (debería ser alto)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(f\"\\nR² Training: {r2_train:.4f}\")\n",
    "print(f\"R² Test: {r2:.4f}\")\n",
    "\n",
    "# 4. Calcula baseline (predecir solo la media)\n",
    "baseline_pred = np.full(len(y_test), y_train.mean())\n",
    "r2_baseline = r2_score(y_test, baseline_pred)\n",
    "print(f\"R² Baseline (media): {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5035173",
   "metadata": {},
   "source": [
    "# Features to implement\n",
    "1. remove linear trend -> fourier terms\n",
    "2. calcular ROI por canal\n",
    "3. elasticnet\n",
    "4. lasso\n",
    "5. bayesian ridge\n",
    "6. probar robyn/lightMMM\n",
    "7. xboost?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065b5ec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heineken_mmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
